# CrewAI Collaboration Skill

OpenClawとCrewAIを効率的に、かつAPIコストを抑えながら共存させるための設計指針。

## 1. アーキテクチャの基本原則：責務の完全分離
OpenClawの強み（外部システムとのインターフェース、自律ループ）と、CrewAIの強み（専門的役割の協調）を衝突させず、階層化して実装すること。

* **OpenClawの役割:** システム全体のフロントエンド、トリガー検知、ユーザーとの対話、最終的なVirtuals Protocol（ACP）へのトランザクション送信。
* **CrewAIの役割:** OpenClawから「カスタムツール（関数）」として呼び出されるバックエンドの推論・タスク実行エンジン。
* **禁止事項:** CrewAIの全エージェントの会話ログをOpenClawのメインループ（Memory）に直接流し込むこと。これは即座にコンテキストの肥大化とAPI上限の枯渇を招く。

## 2. APIトークン消費の劇的削減策（最重要課題）
CrewAIの実行において以下を必須実装とする。

* **結果の要約（Summarization）:** CrewAIプロセスの最終出力は、OpenClawが理解できる最小限のJSON（結論、実行概要、次ステップ）のみに絞り込むこと。
* **LLMモデルの使い分け:** CrewAI内の役割に応じてモデルを切り替える。
    * 情報収集・整形エージェント → 軽量/安価なモデル（Claude 3.5 Haiku, Gemini 2.5 Flash等、またはローカルLLM）
    * 最終意思決定・決済承認エージェント → 高度なモデル（Claude 3.5 Sonnet以上）
* **キャッシュの活用:** CrewAIのタスク実行において、同一のツール呼び出し結果をキャッシュし、無駄な外部APIリクエストと推論を省略する設定（`cache=True`）を有効化すること。

## 3. 実装ガイド
* **詳細ログの分離:** CrewAIの実行詳細ログ（Raw Log）はメインメモリに流さず、ワークスペース内の `logs/crewai/` ディレクトリにファイルとして保存する。OpenClawは必要に応じてそのファイルを読み込む。
